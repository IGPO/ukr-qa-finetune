{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83e\udd16 Generate Ukrainian QA Dataset with GPT-4\n",
        "This notebook generates questions and answers from academic chunks using OpenAI GPT-4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install openai tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import openai\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Insert your OpenAI API key\n",
        "openai.api_key = \"sk-...\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load text chunks\n",
        "with open('/content/chunks.txt', 'r', encoding='utf-8') as f:\n",
        "    chunks = [line.strip() for line in f if len(line.strip()) > 30]\n",
        "print(f\"Loaded {len(chunks)} chunks.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_prompt(text):\n",
        "    return f\"\"\"\n",
        "\u0422\u0438 \u2014 \u043e\u0441\u0432\u0456\u0447\u0435\u043d\u0438\u0439 \u043c\u043e\u0432\u043d\u0438\u0439 \u0430\u0441\u0438\u0441\u0442\u0435\u043d\u0442. \u041f\u0440\u043e\u0447\u0438\u0442\u0430\u0439 \u043d\u0430\u0441\u0442\u0443\u043f\u043d\u0438\u0439 \u0444\u0440\u0430\u0433\u043c\u0435\u043d\u0442 \u0430\u043a\u0430\u0434\u0435\u043c\u0456\u0447\u043d\u043e\u0433\u043e \u0442\u0435\u043a\u0441\u0442\u0443 \u0442\u0430 \u0437\u0433\u0435\u043d\u0435\u0440\u0443\u0439 2\u20133 \u043f\u0438\u0442\u0430\u043d\u043d\u044f \u0437 \u0432\u0456\u0434\u043f\u043e\u0432\u0456\u0434\u044f\u043c\u0438. \u0424\u043e\u0440\u043c\u0430\u0442 \u0432\u0456\u0434\u043f\u043e\u0432\u0456\u0434\u0456 \u2014 \u0441\u043f\u0438\u0441\u043e\u043a \u043e\u0431'\u0454\u043a\u0442\u0456\u0432 JSON, \u043a\u043e\u0436\u0435\u043d \u0437 \u044f\u043a\u0438\u0445 \u043c\u0430\u0454 \u043f\u043e\u043b\u044f \"question\" \u0442\u0430 \"answer\". \u0422\u0435\u043a\u0441\u0442:\n",
        "\n",
        "{text}\n",
        "\n",
        "\u041f\u043e\u0432\u0435\u0440\u043d\u0438 \u043b\u0438\u0448\u0435 \u0441\u043f\u0438\u0441\u043e\u043a JSON-\u043e\u0431'\u0454\u043a\u0442\u0456\u0432.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_qa(text):\n",
        "    prompt = build_prompt(text)\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.5\n",
        "        )\n",
        "        content = response['choices'][0]['message']['content']\n",
        "        return json.loads(content)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "alpaca_data = []\n",
        "for chunk in tqdm(chunks[:20]):\n",
        "    qa_pairs = generate_qa(chunk)\n",
        "    for pair in qa_pairs:\n",
        "        alpaca_data.append({\n",
        "            \"instruction\": \"Answer the question based on the text.\",\n",
        "            \"input\": f\"Text: {chunk}\\nQuestion: {pair['question']}\",\n",
        "            \"output\": pair['answer']\n",
        "        })\n",
        "\n",
        "with open('qa_dataset.jsonl', 'w', encoding='utf-8') as f:\n",
        "    for item in alpaca_data:\n",
        "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
        "\n",
        "print(\"\u2705 Saved as qa_dataset.jsonl\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}