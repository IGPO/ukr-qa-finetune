{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXZVY2Qf2u8M"
      },
      "source": [
        "# ðŸ¤– Generate Ukrainian QA Dataset with GPT-4\n",
        "This notebook generates questions and answers from academic chunks using OpenAI GPT-4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLn_V04W2u8M"
      },
      "outputs": [],
      "source": [
        "!pip install tqdm\n",
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFUKhKLQ2u8N"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Insert your OpenAI API key\n",
        "key = \"sk-\"\n",
        "client = OpenAI(api_key=key)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f_p0Dq62u8N"
      },
      "outputs": [],
      "source": [
        "# Load text chunks\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()  # load chunks.txt\n",
        "\n",
        "# read file\n",
        "with open(\"chunks.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    chunks = [line.strip() for line in f if len(line.strip()) > 30]\n",
        "\n",
        "print(f\"Loaded {len(chunks)} chunks\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lq2MjDOv2u8N"
      },
      "outputs": [],
      "source": [
        "def build_prompt(text):\n",
        "    return f\"\"\"\n",
        "You are a highly skilled academic assistant. Read the following Ukrainian technical academic text and generate 3â€“5 **meaningful**, **detailed** QA pairs. Each question should be specific, based on the actual content (not general), and each answer should be concise but technically accurate.\n",
        "\n",
        "Format your output as a JSON list with elements like:\n",
        "{{\"question\": \"...\", \"answer\": \"...\"}}\n",
        "\n",
        "Only return the JSON list â€” no comments or explanations.\n",
        "\n",
        "Text:\n",
        "{text}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIfyjrih2u8N"
      },
      "outputs": [],
      "source": [
        "def generate_qa(text):\n",
        "    prompt = build_prompt(text)\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.5\n",
        "        )\n",
        "        content = response.choices[0].message.content\n",
        "        return json.loads(content)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k00Mf8Qh2u8N"
      },
      "outputs": [],
      "source": [
        "alpaca_data = []\n",
        "for chunk in tqdm(chunks[:100]):\n",
        "    qa_pairs = generate_qa(chunk)\n",
        "    for pair in qa_pairs:\n",
        "        alpaca_data.append({\n",
        "            \"instruction\": \"Answer the question based on the text.\",\n",
        "            \"input\": f\"Text: {chunk}\\nQuestion: {pair['question']}\",\n",
        "            \"output\": pair['answer']\n",
        "        })\n",
        "\n",
        "with open('qa_dataset.jsonl', 'w', encoding='utf-8') as f:\n",
        "    for item in alpaca_data:\n",
        "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
        "\n",
        "print(\"âœ… Saved as qa_dataset.jsonl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGFAbH7C4bkM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
